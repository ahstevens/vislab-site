<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- TemplateBeginEditable name="doctitle" -->
<title>VTDP Pattern Comparisons</title>
<!-- TemplateEndEditable -->
<!-- TemplateBeginEditable name="head" --><!-- TemplateEndEditable -->
<link href="../VDTPs.css" rel="stylesheet" type="text/css" />
<style type="text/css">
<!--
@import url("VTDPs.css");
-->
</style>
</head>

<body>
<table width="800" border="0" align="center" cellpadding="0" cellspacing="0">
  <tr>
    <td colspan="9" align="left" valign="top"><!-- TemplateBeginEditable name="menu" --><!-- TemplateEndEditable --></td>
  </tr>
  <tr>
    <td height="19" colspan="9" align="left" valign="top"><table width="@@(width)@@" border="0" align="left" cellpadding="0" id="CONTENT">
      <tr>
        <td width="794" align="left" valign="top"><!-- TemplateBeginEditable name="PageTitle" class="Title" -->
          <div align="center" class="Title">VTDP: Pattern Comparisons  in a Large Information Space </div>
        <!-- TemplateEndEditable --><!-- TemplateBeginEditable name="body" -->
  <p class="bodytext">&nbsp;</p>
  <p class="bodytext">Sometimes we need to compare details in a large information space such as a high resolution image or a large and complex network. Cognitive tasks are to find similarities and differences between small scale patterns.  </p>
  <p><span class="HH2">Example 1:</span>  a map display where we need to compare small scale geological features on one part of a map with small scale features in another part of a map.     </p>
  <p><span class="HH2">Example 2: </span>an X-Ray image where we need to compare widely separated small stuctures possible representing cancerous nodules. </p>
   <span class="HH2">Example 3:</span>  a net work diagram showing metabolic pathways in a cell. We need to compare small sub systems of metabolic pathways across species. 
   <p class="bodytext">Any pattern comparison involves loading some  aspect of one pattern into visual working memory, to be later compared to some  other pattern.  Pattern comparisons are  far more efficient if the transfer of attention between one pattern and another  can be made using eye movements, because in this case the information only  needs to be held for a fraction of a second. </p>
  <table width="759" border="1">
    <caption class="HH2">
      An overview of the process of visual pattern comparisons
      </caption>
    <tr>
      <td width="749"><ol>
        <li><em>Execute an  epistemic action by navigating to location of first pattern.</em></li>
        <li><em>Retain subset of first  pattern in visual working memory.</em></li>
        <li><em>Execute an epistemic action by navigating  to candidate location of a comparison pattern.</em></li>
        <li><em>Compare working memory pattern with part  of pattern at candidate location.</em><br />
                      <em> 4.1  If a suitable match is found terminate  search.</em><br />
                      <em>4.2   If a partial match is found,  navigate  back and forth between candidate location and master  pattern location loading additional subsets  of candidate pattern into visual working memory and making comparison until a suitable  match or a mismatch is found.</em></li>
        <li><em>If a mismatch is  found repeat </em></li>
      </ol></td>
    </tr>
  </table>
  <p class="HH1">IMPLEMENTATIONS</p>
  <p><span class="HH1">Zooming</span>  </p>
  <p>The simplest and most common implementation of the Pattern Comparisons VTDP is to allow for  zooming (scale change) of the data display [1].   However, since it can take several seconds to transition from one area  of detail to another using this method it can be cognitively inefficient and  place a burden on working memory.   </p>
  <p><span class="HH2">Use Guideline: </span>Zooming is useful when comparisons are infrequent and where the patterns to be compared are simple. Consider using Magnifying Windows or Linked Snapshots when the patterns to be compared are more complex.  </p>
  <p><span class="HH2">Implementation Guideline:</span> The optimal zoom rate is around a scale change of 4x/sec. </p>
  <p><span class="HH1">Magnifying Windows </span>
  </p>
  <p>Interactive magnifying windows  can be attached  by the user to focal points on an overview display. The focus of the window can be controlled either by dragging at the focal point. Additionally fine scale movement can be carried out by dragging in the magnifying window itself [5]. The problem with this  solution can be the overhead involved in setting up the extra windows.  If they are frequently needed they should  always be present.  There are many  tradeoffs in the amount of screen space devoted to magnifying windows and  overview and the best design will depend on the specific application.</p>
  <p><img src="Images/F11.17_GeoZui.jpg" alt="GeoZuiMagWindows" width="600" height="468" /></p>
  <p><span class="HH2">Use Guideline: </span>Provide  magifying windows when frequent comparisons of detailed areas are needed. These are especially valuable when the patterns to be compared exceed visual working memory capacity.</p>
  <p><span class="HH2">Use Guideline: </span>The magnifying factor supported by a magnifying window should be less than 30x. </p>
  <span class="HH2">Cognitive Guideline: </span>Use extra windows when patterns to be compared are too complex to be held in visual working memory
<p><span class="HH1">Snapshot Gallery with Zooming </span>  </p>
  <p>Small snapshots saved  to a  gallery supports side-by-side comparisons of complex patterns using eye movements. This method can be used to enhance zooming alone, or a viewer with magnifying windows. Links back to locations in the larger image can provide context. </p>
  <p><img src="Images/CancerCells.jpg" alt="CancerCellsScripps" width="660" height="371" /></p>
  <p><span class="HH2">Use Guideline: </span>Provide  snapshot gallery support when frequent comparisons of <em>many</em> detailed areas are needed.  </p>
  <span class="HH2">Implementation Guideline: </span>Provide links back to the originating image to give context. 
  <p class="HH1">Geometric Fisheye View  </p>
  <p>In the geometric fisheye view, a data map is distorted so that some  regions are magnified and others are minified to compensate [2].   Distortion occurs at the boundaries between the different scales. Because of the distortion broblem large magnification factors should be avoided. Geometric Fisheye View can have multiple foci of magnification and this is useful for </p>
  <span class="HH2">Use Guideline: </span>Use geometric fisheye view support where comparisons can be made with &lt; 5x magnification.
<p class="HH1">Nested Graph With Intelligent Zoom </p>
  <p>See also [VTDP: drill down, close out with heirarchical aggregation]  </p>
  <p>If the data for comparison is a large graph, or a set of large graphs, a form of fisheye view can be developed based on the nested structure of the graph. Several different subgraphs can be expanded and thereby compared. In the intelligent zoom method [4] regions not expanded are contracted to save space. There are limitations on the complexity of the sub graphs that will inevitably limit comparisons. At the time of writing these limitations have not been quantified. </p>
  <p><img src="Images/fisheye_view_nondistorted_Neilsen.png" alt="MultiFocusFisheye" width="668" height="517" /></p>
  <span class="HH2">Guidelines: </span>To be determined
<p class="HH1">References</p>
  <ol>
    <li>Bederson, B. and Hollan, J. (1994). Pad++: A zooming graphical interface for exploring alternate interface physics. Proceedings of UIST &quot;94, ACM, 17-36. </li>
    <li>Carpendale, M. S. T., Cowperthwaite, D. J., &amp; Fracchia, F. D. (1997). Making distortions comprehensible. In Proc IEEE Visual Languages, 36-45.</li>
    <li>Plumlee, M. and Ware, C. (2002). Modeling performance for zooming vs multi-window interfaces based on visual working memory. Advanced Visual Interfaces, Trento, Italy, May Proceedings, 59-68. </li>
    <li>Schaffer, D, Zuo, Z, Bartram, L., Dill, D Dubs, S., Greenberg, S. and  Roseman, M. (1993). “Comparing fisheye and full-zoom techniques for navigation of hierarchically clustered networks,” in Proc. Graphics Interface (GI ’93), 87–96.</li>
    <li>Ware, C. and Lewis, M. (1995). The DragMag image magnifier. CHI '95 Conference Companion and Conference Video Proceedings, ACM, 407-408. </li>
  </ol>
  <!-- TemplateEndEditable --></td>
      </tr>
    </table></td>
  </tr>
  <tr>
    <td height="19" colspan="9" align="center" valign="top"><p>&nbsp;</p></td>
  </tr>
  <tr>
    <td width="277" height="58" align="center" valign="top">&nbsp;</td>
    <td width="27" align="center" valign="top">&nbsp;</td>
    <td colspan="5" align="center" valign="middle" class="tinytext"><span class="tiny">Visual Thinking Design Patterns are partially funded by the DARPA XDATA project </span></td>
    <td width="24" align="center" valign="top">&nbsp;</td>
    <td width="272" align="center" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td align="center" valign="top">&nbsp;</td>
    <td align="center" valign="top">&nbsp;</td>
    <td colspan="5" align="center" valign="middle" class="tinytext">&nbsp;</td>
    <td align="center" valign="top">&nbsp;</td>
    <td align="center" valign="top">&nbsp;</td>
  </tr>
</table>
</body>
</html>
